# -*- coding: utf-8 -*-
"""CÃ³pia de Workshop_API.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ivucBcKWN0KMs4dKi0emZpo2dxzQOeTO
"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

caminho_in = ('/content/drive/My Drive/Dados/') # caminho especificio do arquivo antes de ser programado
caminho_out = ('/content/drive/My Drive/Dados/') # o /data Ã© a pasta do marquinho e o /content Ã© o caminho dele out vai sair o caminho depois programado

file1 = caminho_in + "2024Atracacao.txt"
with open (file1, 'r', encoding='UTF-8') as f:
  linhas = f.readlines()
  for i in range (0, 5):
    print(f"Linha {i+1}: {linhas[i]}")

df1 = pd.read_csv(file1, low_memory=False, sep=';', encoding = 'UTF-8', decimal =",")
df1.info()

file2 = caminho_in + '2023Atracacao.txt'
with open(file2, 'r', encoding='UTF-8') as f:
    linhas = f.readlines()
    for i in range(0, 5):
        print(f"Linha {i+1}: {linhas[i]}")

df2 = pd.read_csv(file2, low_memory=False, sep=';', encoding = 'UTF-8', decimal =",")
df2.info()

csv_final = [file1, file2]
ANTAQ_Int = pd.DataFrame()
for csv_final in csv_final:
    df = pd.read_csv(csv_final, sep = ';')
    ANTAQ_Int = pd.concat([ANTAQ_Int, df], ignore_index=True)
ANTAQ_Int.info()

ANTAQ_Int.head(5)

ANTAQ_Int.tail(5)

colunas_interesse = ['IDAtracacao','IDBerco',
                     'Data AtracaÃ§Ã£o', 'Data Chegada',
                     'Data DesatracaÃ§Ã£o','Data InÃ­cio OperaÃ§Ã£o',
                     'Data TÃ©rmino OperaÃ§Ã£o']

ANTAQ = ANTAQ_Int.dropna(subset=colunas_interesse)
ANTAQ.info()

ANTAQ['Data Chegada'] = pd.to_datetime(ANTAQ['Data Chegada'], format='%d/%m/%Y %H:%M:%S')
ANTAQ['Data AtracaÃ§Ã£o'] = pd.to_datetime(ANTAQ['Data AtracaÃ§Ã£o'], format='%d/%m/%Y %H:%M:%S')
ANTAQ['Data InÃ­cio OperaÃ§Ã£o'] = pd.to_datetime(ANTAQ['Data InÃ­cio OperaÃ§Ã£o'], format='%d/%m/%Y %H:%M:%S')
ANTAQ['Data TÃ©rmino OperaÃ§Ã£o'] = pd.to_datetime(ANTAQ['Data TÃ©rmino OperaÃ§Ã£o'], format='%d/%m/%Y %H:%M:%S')
ANTAQ['Data DesatracaÃ§Ã£o'] = pd.to_datetime(ANTAQ['Data DesatracaÃ§Ã£o'], format='%d/%m/%Y %H:%M:%S')

ANTAQ['Tempo_espera_chegada'] = (ANTAQ['Data AtracaÃ§Ã£o'] - ANTAQ['Data Chegada']).dt.total_seconds() / 3600
ANTAQ['Tempo_espera_inicial'] = (ANTAQ['Data InÃ­cio OperaÃ§Ã£o'] - ANTAQ['Data AtracaÃ§Ã£o']).dt.total_seconds() / 3600
ANTAQ['Tempo_operacao'] = (ANTAQ['Data TÃ©rmino OperaÃ§Ã£o'] - ANTAQ['Data InÃ­cio OperaÃ§Ã£o']).dt.total_seconds() / 3600
ANTAQ['Tempo_espera_final'] = (ANTAQ['Data DesatracaÃ§Ã£o'] - ANTAQ['Data TÃ©rmino OperaÃ§Ã£o']).dt.total_seconds() / 3600
ANTAQ['Tempo_ocupacao'] = (ANTAQ['Data DesatracaÃ§Ã£o'] - ANTAQ['Data AtracaÃ§Ã£o']).dt.total_seconds() / 3600

ANTAQ.info()

duplicados = ANTAQ.duplicated(subset=['IDAtracacao'], keep=False)
if duplicados.any():
    print("Existem valores duplicados.")
    print(ANTAQ[duplicados])
else:
    print("Coluna com valores unicos.")

coluna = 'Complexo PortuÃ¡rio'
CP = ANTAQ[coluna].value_counts().sort_index()
print(f"Total de operaÃ§Ãµes por {coluna}:")
print(CP)

porto = 'Santos'
navegacao = 'Longo Curso'
filtro =  ANTAQ[(ANTAQ['Complexo PortuÃ¡rio'] == porto) &
                (ANTAQ['Tipo de NavegaÃ§Ã£o da AtracaÃ§Ã£o'] == navegacao)]
tabela = filtro.groupby('BerÃ§o').agg({'BerÃ§o': 'count'}).rename(columns={'BerÃ§o': 'Total'})
print(tabela)

filtro.info()

colunas_interesse1 = ['IDAtracacao','CDTUP','BerÃ§o','Porto AtracaÃ§Ã£o', 'Complexo PortuÃ¡rio','Tipo de NavegaÃ§Ã£o da AtracaÃ§Ã£o',
                      'Data Chegada','Data AtracaÃ§Ã£o','Data InÃ­cio OperaÃ§Ã£o','Data TÃ©rmino OperaÃ§Ã£o','Data DesatracaÃ§Ã£o',
                      'Tempo_espera_chegada', 'Tempo_espera_inicial','Tempo_operacao', 'Tempo_espera_final', 'Tempo_ocupacao']
ANTAQ[colunas_interesse1].to_csv(caminho_out + 'Atracacao_final.csv', index=False)

drive.mount('/content/drive')
arquivo = '/content/drive/My Drive/Dados/Atracacao_final.csv'
with open (arquivo, 'r', encoding='UTF-8') as f:
    linhas = f.readlines()
    for i in range(0, 5):
        print(f"Linha {i+1}: {linhas[i]}")

df = pd.read_csv(arquivo, low_memory=False, sep=',', encoding='UTF-8')
df.head()

file3 = caminho_in+'2024Carga.txt'
with open (file3, 'r', encoding='UTF-8') as f:
    linhas = f.readlines()
    for i in range(0, 5):
        print(f"Linha {i+1}: {linhas[i]}")

df2 = pd.read_csv(file3, low_memory=False, sep=';', encoding = 'UTF-8', decimal =",")
df2.info()

df2.head(5)

file4 = caminho_in+'2023Carga.txt'
with open(file3, 'r', encoding='UTF-8') as f:
    linhas = f.readlines()
    for i in range(0, 5):
        print(f"Linha {i+1}: {linhas[i]}")

csv_final = [file3, file4]
Carga_Int = pd.DataFrame()
for csv_final in csv_final:
    df = pd.read_csv(csv_final, sep=';', low_memory=False)
    Carga_Int = pd.concat([Carga_Int, df], ignore_index=True)
Carga_Int.info()

duplicados2 = Carga_Int.duplicated(subset=['IDAtracacao'], keep=False)
if duplicados2.any():
    print("Existem valores duplicados.")
else:
    print("Coluna com valores unicos.")

sentido = 'Embarcados'
navegacao = 'Longo Curso'
cargas = ['1201','1005']
operacao = 'Exclusivo'
df3 = Carga_Int[(Carga_Int['Sentido'] == sentido) &
                (Carga_Int['Tipo NavegaÃ§Ã£o'] == navegacao) &
                (Carga_Int['CDMercadoria'].isin(cargas)) &
                (Carga_Int['STSH4'] == operacao)]
df3.info()

coluna = ['IDAtracacao', 'CDMercadoria', 'Sentido',]
coluna_valor = 'VLPesoCargaBruta'
cargas = df3.groupby(coluna)[coluna_valor].sum().reset_index()

cargas.head(5)

final = pd.merge(ANTAQ, cargas, left_on='IDAtracacao', right_on='IDAtracacao', how='inner')

final.info()

final.head(5)

final

final.mean(numeric_only=True)

colunas_desejadas = ['Tempo_espera_chegada', 'Tempo_espera_inicial',
                     'Tempo_operacao', 'Tempo_espera_final',
                     'Tempo_ocupacao', 'VLPesoCargaBruta']

media_selecionada = final[colunas_desejadas].mean(numeric_only=True)
pd.options.display.float_format = '{:.6f}'.format
print(media_selecionada)

import matplotlib as plt
import seaborn as sns
sns.set(style='whitegrid', palette="deep", font_scale=1.1, rc={"figure.figsize": [8, 5]})

espera_atracar = final['Tempo_espera_chegada']
espera_atracar.describe()

sns.histplot(espera_atracar)

final.to_csv(caminho_out+'Base_final_ANTAQ.csv', index=False)

file5 = caminho_in+'2024TemposAtracacao.txt'
with open (file3, 'r', encoding='UTF-8') as f:
    linhas = f.readlines()
    for i in range(0, 5):
        print(f"Linha {i+1}: {linhas[i]}")

file6 = caminho_in+'2023TemposAtracacao.txt'
with open (file3, 'r', encoding='UTF-8') as f:
    linhas = f.readlines()
    for i in range(0, 5):
        print(f"Linha {i+1}: {linhas[i]}")

file7 = caminho_in+'2024TemposAtracacaoParalisacao.txt'
with open (file3, 'r', encoding='UTF-8') as f:
    linhas = f.readlines()
    for i in range(0, 5):
        print(f"Linha {i+1}: {linhas[i]}")

file8 = caminho_in+'2023TemposAtracacaoParalisacao.txt'
with open (file3, 'r', encoding='UTF-8') as f:
    linhas = f.readlines()
    for i in range(0, 5):
        print(f"Linha {i+1}: {linhas[i]}")

csv_final = [file5, file7]
Carga_Int = pd.DataFrame()
for csv_final in csv_final:
    df = pd.read_csv(csv_final, sep=';', low_memory=False)
    Carga_Int = pd.concat([Carga_Int, df], ignore_index=True)
Carga_Int.info()

csv_final = [file6, file8]
Carga_Int = pd.DataFrame()
for csv_final in csv_final:
    df = pd.read_csv(csv_final, sep=';', low_memory=False)
    Carga_Int = pd.concat([Carga_Int, df], ignore_index=True)
Carga_Int.info()

import pandas as pd

# Lista com os arquivos
arquivos = [file5, file7]

# DataFrame para consolidar
Carga_Int = pd.DataFrame()

# Leitura e concatenaÃ§Ã£o
for arquivo in arquivos:
    df = pd.read_csv(arquivo, sep=';', low_memory=False)
    Carga_Int = pd.concat([Carga_Int, df], ignore_index=True)

# Verifica se a coluna existe e trata
if 'DescricaoTempoDesconto' in Carga_Int.columns:
    # Seleciona as colunas
    df_filtrado = Carga_Int[['IDAtracacao', 'DescricaoTempoDesconto']].copy()

    # Trata valores: transforma em string e remove espaÃ§os
    df_filtrado['DescricaoTempoDesconto'] = df_filtrado['DescricaoTempoDesconto'].astype(str).str.strip()

    # Remove vazios e NaNs
    df_filtrado = df_filtrado[df_filtrado['DescricaoTempoDesconto'] != '']
    df_filtrado = df_filtrado[df_filtrado['DescricaoTempoDesconto'].str.lower() != 'nan']

    # Exporta para CSV
    df_filtrado.to_csv('saida_filtrada_2.csv', index=False, encoding='utf-8-sig')

    print("Arquivo gerado com sucesso sem nenhum NaN ou vazio ðŸ§¼âœ…")
else:
    print("âš ï¸ Coluna 'DescricaoTempoDesconto' nÃ£o encontrada em um dos arquivos.")

import pandas as pd

# Lista com os arquivos
arquivos = [file6, file8]

# DataFrame para consolidar
Carga_Int = pd.DataFrame()

# Leitura e concatenaÃ§Ã£o
for arquivo in arquivos:
    df = pd.read_csv(arquivo, sep=';', low_memory=False)
    Carga_Int = pd.concat([Carga_Int, df], ignore_index=True)

# Verifica se a coluna existe e trata
if 'DescricaoTempoDesconto' in Carga_Int.columns:
    # Seleciona as colunas
    df_filtrado_2 = Carga_Int[['IDAtracacao', 'DescricaoTempoDesconto']].copy()

    # Trata valores: transforma em string e remove espaÃ§os
    df_filtrado_2['DescricaoTempoDesconto'] = df_filtrado_2['DescricaoTempoDesconto'].astype(str).str.strip()

    # Remove vazios e NaNs
    df_filtrado_2 = df_filtrado_2[df_filtrado_2['DescricaoTempoDesconto'] != '']
    df_filtrado_2 = df_filtrado_2[df_filtrado_2['DescricaoTempoDesconto'].str.lower() != 'nan']

    # Exporta para CSV
    df_filtrado_2.to_csv('saida_filtrada_2.csv', index=False, encoding='utf-8-sig')

    print("Arquivo gerado com sucesso sem nenhum NaN ou vazio ðŸ§¼âœ…")
else:
    print("âš ï¸ Coluna 'DescricaoTempoDesconto' nÃ£o encontrada em um dos arquivos.")

from google.colab import files
import pandas as pd

# DicionÃ¡rio com seus DataFrames (substitua pelas suas variÃ¡veis reais)
dataframes_para_exportar = {
    "motivos_portos_2024": df_filtrado_2,
    "motivos_portos_2023": df_filtrado
}

# VerificaÃ§Ã£o e exportaÃ§Ã£o
for nome_df, df in dataframes_para_exportar.items():
    try:
        # Verifica se Ã© um DataFrame (ou Series, que tambÃ©m pode ser exportada)
        if isinstance(df, (pd.DataFrame, pd.Series)):
            nome_arquivo = f"{nome_df}.csv"

            # Converte Series para DataFrame se necessÃ¡rio
            if isinstance(df, pd.Series):
                df = df.to_frame()

            df.to_csv(nome_arquivo, index=True, encoding='utf-8-sig')  # index=True mantÃ©m os Ã­ndices
            files.download(nome_arquivo)
            print(f"âœ… {nome_df} exportado como {nome_arquivo}")
        else:
            print(f"âš ï¸ {nome_df} nÃ£o Ã© um DataFrame/Series (tipo: {type(df)})")
    except Exception as e:
        print(f"âŒ Erro ao exportar {nome_df}: {str(e)}")

print("\nTodos os arquivos exportados com sucesso!")

#CODIGO QUE TIREI DA CABEÃ‡A

import pandas as pd

# Corrige pesos que vÃªm como texto com ponto e vÃ­rgula (ou sÃ³ vÃ­rgula)
def converter_peso(valor):
    if isinstance(valor, str):
        valor = valor.replace('.', '').replace(',', '.')
    try:
        return float(valor)
    except:
        return None

# Aplica a conversÃ£o corretamente
for df in [Carga_Int, final]:
    if 'VLPesoCargaBruta' in df.columns:
        df['VLPesoCargaBruta'] = df['VLPesoCargaBruta'].apply(converter_peso)

# Verifique se agora os valores sÃ£o realmente float
print(final['VLPesoCargaBruta'].dtypes)

produtividade = final.groupby('CDTUP')['VLPesoCargaBruta'].sum().sort_values(ascending=False)
print("\nProdutividade por terminal (CORRIGIDO DE VERDADE):")
print(produtividade)

# Converter para nÃºmero
final['VLPesoCargaBruta'] = pd.to_numeric(final['VLPesoCargaBruta'], errors='coerce')

# Calcular a produtividade (carga por hora)
final['Carga_por_Hora'] = final['VLPesoCargaBruta'] / final['Tempo_operacao']

# Agrupar por terminal e tirar mÃ©dia
carga_hora_media = final.groupby('CDTUP')['Carga_por_Hora'].mean().sort_values(ascending=False)

print("MÃ©dia de carga movimentada por hora de operaÃ§Ã£o (por terminal):")
print(carga_hora_media)

## CORRETO QUESTÃƒO 1

import pandas as pd
import numpy as np

# Converte as colunas para nÃºmeros
final['VLPesoCargaBruta'] = pd.to_numeric(final['VLPesoCargaBruta'], errors='coerce')
final['Tempo_operacao'] = pd.to_numeric(final['Tempo_operacao'], errors='coerce')

# Remove linhas com dados faltando ou valores estranhos
final.dropna(subset=['VLPesoCargaBruta', 'Tempo_operacao'], inplace=True)

# Remove pesos absurdos (ex: acima de 1 milhÃ£o de toneladas) e tempos invÃ¡lidos
final = final[(final['VLPesoCargaBruta'] > 0) & (final['VLPesoCargaBruta'] < 1e6)]
final = final[(final['Tempo_operacao'] > 0) & (final['Tempo_operacao'] < 1e6)]

# Calcula a produtividade
final['Carga_por_Hora'] = final['VLPesoCargaBruta'] / final['Tempo_operacao']

# Agrupa por terminal e tira mÃ©dia
carga_hora_media = final.groupby('CDTUP')['Carga_por_Hora'].mean().sort_values(ascending=False)

print("MÃ©dia de carga movimentada por hora de operaÃ§Ã£o (por terminal):")
print(carga_hora_media)

from google.colab import files
import pandas as pd

# DicionÃ¡rio com seus DataFrames (substitua pelas suas variÃ¡veis reais)
dataframes_para_exportar = {
    "carga_hora_media": carga_hora_media
}

# VerificaÃ§Ã£o e exportaÃ§Ã£o
for nome_df, df in dataframes_para_exportar.items():
    try:
        # Verifica se Ã© um DataFrame (ou Series, que tambÃ©m pode ser exportada)
        if isinstance(df, (pd.DataFrame, pd.Series)):
            nome_arquivo = f"{nome_df}.csv"

            # Converte Series para DataFrame se necessÃ¡rio
            if isinstance(df, pd.Series):
                df = df.to_frame()

            df.to_csv(nome_arquivo, index=True, encoding='utf-8-sig')  # index=True mantÃ©m os Ã­ndices
            files.download(nome_arquivo)
            print(f"âœ… {nome_df} exportado como {nome_arquivo}")
        else:
            print(f"âš ï¸ {nome_df} nÃ£o Ã© um DataFrame/Series (tipo: {type(df)})")
    except Exception as e:
        print(f"âŒ Erro ao exportar {nome_df}: {str(e)}")

#TAREFA 3
# Importando as bibliotecas necessÃ¡rias
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ConfiguraÃ§Ãµes para visualizaÃ§Ã£o mais bonita dos grÃ¡ficos
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (15, 8)

# Carregando os dados
atracacao_2023 = pd.read_csv(file6, delimiter=';')
atracacao_2024 = pd.read_csv(file5, delimiter=';')
paralisacao_2023 = pd.read_csv(file8, delimiter=';')
paralisacao_2024 = pd.read_csv(file7, delimiter=';')

# Juntando os dados de paralisaÃ§Ã£o
paralisacao = pd.concat([paralisacao_2023, paralisacao_2024], ignore_index=True)

# Convertendo datas para o formato datetime
paralisacao['DTInicio'] = pd.to_datetime(paralisacao['DTInicio'], dayfirst=True)
paralisacao['DTTermino'] = pd.to_datetime(paralisacao['DTTermino'], dayfirst=True)

# Calculando a duraÃ§Ã£o das paralisaÃ§Ãµes em horas
paralisacao['DuracaoHoras'] = (paralisacao['DTTermino'] - paralisacao['DTInicio']).dt.total_seconds() / 3600

# Extraindo mÃªs e ano para anÃ¡lise sazonal
paralisacao['Mes'] = paralisacao['DTInicio'].dt.month
paralisacao['Ano'] = paralisacao['DTInicio'].dt.year

# Agrupando por motivo, mÃªs e ano
top_motivos = paralisacao.groupby(['DescricaoTempoDesconto', 'Mes', 'Ano']).agg(
    Total_Horas=('DuracaoHoras', 'sum'),
    Total_Paradas=('IDTemposDescontos', 'count')
).reset_index()

top_motivos = top_motivos.sort_values(by='Total_Horas', ascending=False)

# Exibindo os Top 10 motivos com mais horas de paralisaÃ§Ã£o
print(top_motivos.head(10))

# Criando um grÃ¡fico para visualizar os principais motivos
plt.figure(figsize=(15, 8))
sns.barplot(data=top_motivos.head(10), x='DescricaoTempoDesconto', y='Total_Horas', hue='Ano', dodge=True)
plt.title('Top 10 Motivos de Paradas PortuÃ¡rias (2023-2024)', fontsize=20)
plt.xticks(rotation=45)
plt.ylabel('Total de Horas Paradas')
plt.xlabel('Motivo da ParalisaÃ§Ã£o')
plt.show()

paralisacao_2023

#IMPRESSAO TAREFA 3 - 50%
from google.colab import files
import pandas as pd

# DicionÃ¡rio com seus DataFrames (substitua pelas suas variÃ¡veis reais)
dataframes_para_exportar = {
    "top_motivos": top_motivos
}

# VerificaÃ§Ã£o e exportaÃ§Ã£o
for nome_df, df in dataframes_para_exportar.items():
    try:
        # Verifica se Ã© um DataFrame (ou Series, que tambÃ©m pode ser exportada)
        if isinstance(df, (pd.DataFrame, pd.Series)):
            nome_arquivo = f"{nome_df}.csv"

            # Converte Series para DataFrame se necessÃ¡rio
            if isinstance(df, pd.Series):
                df = df.to_frame()

            df.to_csv(nome_arquivo, index=True, encoding='utf-8-sig')  # index=True mantÃ©m os Ã­ndices
            files.download(nome_arquivo)
            print(f"âœ… {nome_df} exportado como {nome_arquivo}")
        else:
            print(f"âš ï¸ {nome_df} nÃ£o Ã© um DataFrame/Series (tipo: {type(df)})")
    except Exception as e:
        print(f"âŒ Erro ao exportar {nome_df}: {str(e)}")

print("\nTodos os arquivos exportados com sucesso!")

top_motivos

print(final.columns)

colunas_interesse = ['Porto AtracaÃ§Ã£o', 'Complexo PortuÃ¡rio']
final_1 = final[colunas_interesse].dropna()

final_1

final_1 = final[['IDAtracacao', 'Porto AtracaÃ§Ã£o', 'Complexo PortuÃ¡rio']].dropna().drop_duplicates()

paralisacao_local = paralisacao.merge(final_1, on='IDAtracacao', how='left')

paralisacao_local['Mes'] = paralisacao_local['DTInicio'].dt.month
paralisacao_local['Ano'] = paralisacao_local['DTInicio'].dt.year

top_motivos_com_local = paralisacao_local.groupby(['DescricaoTempoDesconto', 'Mes', 'Ano',
                                                    'Porto AtracaÃ§Ã£o', 'Complexo PortuÃ¡rio', 'IDAtracacao']).agg(
    Total_Horas=('DuracaoHoras', 'sum'),
    Total_Paradas=('IDTemposDescontos', 'count')
).reset_index()

df_final = pd.merge(
    top_motivos_com_local,
    final_1.drop_duplicates(subset=['Porto AtracaÃ§Ã£o', 'Complexo PortuÃ¡rio']),
    on=['Porto AtracaÃ§Ã£o', 'Complexo PortuÃ¡rio'],
    how='left'  # ou 'inner' se quiser sÃ³ os que existem nos dois
)

df_final

df_final.to_csv("top_motivos_com_local.csv", index=False, encoding='utf-8-sig')
files.download("top_motivos_com_local.csv")

